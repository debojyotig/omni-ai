# omni-ai Environment Configuration

# ============================================================================
# MCP Server
# ============================================================================
# Path to omni-api-mcp MCP server (relative or absolute)
OMNI_API_MCP_PATH=../omni-api-mcp/dist/index.js

# ============================================================================
# LLM Provider Configuration
# ============================================================================
# Runtime switching: Select provider by setting environment variables below.
# No app restart required - switch providers mid-conversation!
# The app auto-detects the configured provider based on these variables.

# ============================================================================
# Anthropic (Direct API) - Default Provider
# ============================================================================
# Required for fallback and direct API access
ANTHROPIC_API_KEY=sk-ant-...

# ============================================================================
# AWS Bedrock - Native Support
# ============================================================================
# Runtime switching: Set these to enable AWS Bedrock
# NOTE: Requires AWS account with Bedrock enabled and Claude model access
# Reference: https://docs.claude.com/en/docs/claude-code/amazon-bedrock.md
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...
# Optional: For temporary credentials via STS, MFA, or IAM roles
# AWS_SESSION_TOKEN=...

# ============================================================================
# GCP Vertex AI - Native Support
# ============================================================================
# Runtime switching: Set these to enable GCP Vertex AI
# NOTE: Requires GCP account with Vertex AI enabled and Claude API access
GCP_PROJECT_ID=your-project-id
GCP_SERVICE_ACCOUNT_KEY={"type":"service_account","project_id":"...","private_key":"..."}

# ============================================================================
# Azure OpenAI - Gateway Support
# ============================================================================
# Runtime switching: Set these to enable Azure OpenAI gateway
# ANTHROPIC_BASE_URL routes requests through your gateway
# The app detects 'azure' in the URL and uses Azure provider
ANTHROPIC_BASE_URL=https://your-gateway.openai.azure.com/
# ANTHROPIC_API_KEY above is also used for Azure

# ============================================================================
# Per-Model Settings (Stored in localStorage)
# ============================================================================
# Configure Max Output Tokens, Temperature, and Max Iterations per provider/model
# in the Settings panel (no environment variables needed).
# Settings persist across browser sessions and provider switches.

# ============================================================================
# omni-api-mcp Service API Keys
# ============================================================================
# These environment variables are passed to the omni-api-mcp subprocess
# Add API keys for services you want to query via omni-api-mcp

# DataDog (for monitoring and observability)
DATADOG_API_KEY=
DATADOG_APP_KEY=
DATADOG_SITE=datadoghq.com

# GitHub (for repository management)
GITHUB_TOKEN=

# Stripe (for payment data)
STRIPE_API_KEY=

# CoinGecko (for cryptocurrency data - public API, no key needed)

# Add other service API keys as needed...

# ============================================================================
# Claude Agent SDK Settings
# ============================================================================
# Streaming Input Mode (recommended - default: true)
# Reference: https://docs.claude.com/en/api/agent-sdk/streaming-vs-single-mode.md
# - true (default): Use AsyncGenerator for long-lived, stateful processing
#   Better for: Interactive chat apps, multi-turn conversations
# - false: Use string for stateless, single-message processing
#   Better for: Lambda/serverless, one-shot responses
USE_STREAMING_INPUT_MODE=true

# ============================================================================
# Application Settings
# ============================================================================
# Next.js
NEXT_PUBLIC_APP_URL=http://localhost:3000

# Node environment
NODE_ENV=development
